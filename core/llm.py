import os
from typing import Literal, Optional, Iterator
from openai import OpenAI


class OpenAICompatibleLLM:
    def __init__(
        self,
        model: Optional[str] = None,
        base_url: Optional[str] = None,
        api_key: Optional[str] = None,
        timeout: Optional[int] = None,
    ):
        self.model = model or os.getenv("LLM_MODEL")
        self.base_url = base_url or os.getenv("LLM_BASE_URL")
        self.api_key = api_key or os.getenv("LLM_API_KEY")
        if not all([self.model, self.base_url, self.api_key]):
            raise Exception("æ¨¡å‹åç§°ã€è®¿é—®ç½‘å€ã€APIå¯†é’¥éœ€è¦æ˜¾å¼æŒ‡å®šæˆ–åœ¨.envæ–‡ä»¶ä¸­å®šä¹‰")
        self.provider = self._auto_detect_provider()
        self.timeout = timeout or int(os.getenv("LLM_TIMEOUT", "60"))

        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
            timeout=self.timeout,
        )

    def _auto_detect_provider(self) -> str:
        if "api.siliconflow.cn" in self.base_url:
            return "SiliconFlow"
        elif "api.deepseek.com" in self.base_url:
            return "DeepSeek"
        elif "dashscope.aliyuncs.com" in self.base_url:
            return "Qwen"
        elif "localhost:11434" in self.base_url:
            return "Ollama"
        else:
            return "Unknown"

    def invoke(self, messages: list[dict[str, str]], **kwargs) -> str:
        print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨{self.provider}:{self.model}æ¨¡å‹")
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                **kwargs,
            )
            print("âœ… LLMå“åº”æˆåŠŸ")
            return response.choices[0].message.content
        except Exception as e:
            print("â›” LLMè°ƒç”¨å¤±è´¥")
            return str(e)
    
    def stream_invoke(self, messages: list[dict[str, str]], **kwargs) -> Iterator[str]:
        print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨{self.provider}:{self.model}æ¨¡å‹")
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                stream=True,
                **kwargs,
            )
            print("âœ… LLMå“åº”æˆåŠŸ")
            for chunk in response:
                content = chunk.choices[0].delta.content
                if content:
                    yield content
            yield "\n"
        except Exception as e:
            print("â›” LLMè°ƒç”¨å¤±è´¥")
            yield str(e)
